import requests
import pandas
import numpy
import re
import csv
import time

L = []

from bs4 import BeautifulSoup
#### page info ###
for k in range (1,378):
    k=str(k)
    time.sleep(30)
    page = requests.get("https://postcode.my/search/?keyword=&state=Johor&page="+k)
#### check page status (will come 200 if the page is ok) 
    page.status_code
### call Library
    soup = BeautifulSoup(page.content, 'html.parser')
### Find rows 
    rows = soup.find_all(class_="col-lg-12 col-md-12 col-sm-12 col-xs-12")
## create list by append

    for row in rows:
        cols = row.find_all("td")
        cols = [x.text.strip() for x in cols]
        L.append(cols)

## convert to numpy array and reshape to 4 columns 
cols = ['LOCATION','AREA','STATE','POSTCODE']
PDTABLE = pandas.DataFrame(numpy.array(L).reshape(-1,4),columns = cols)
PDTABLE.to_csv('Johor.csv')
